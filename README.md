Just a personal project for trying to get into the quantitative finance world.
I initially tried to predict both return and risk with one single model with time series cross validation for unbiasness, but that did not work like intended. Risk prediction was fine, 
but returns were absolutely useless. The return prediction was a straight line, no fluctuation whatsoever; so i figured, it must have been because discrete returns are so noisy that they mask the true patterns.
So I tried predicting moving average return and total return over a horizon simutaneously. That turned out even worse for both risk and return than the first iteration. That meant 2 things for me: discrete returns actually have predictive power for risk prediction; one single set of weights and biases can't optimize both risk and return prediction, they're like fucking orthogonal to each other (very counterintuitive). 
So I tried 2 different models for 2 prediction tasks. I didnt have enough time so I went with the suggestion chatgpt gave me, which was using LSTM for risk and MLP for returns (its reasoning was LSTM captures temporal patterns well but returns dont exhibit much temporal patterns - only price does, so LSTM might suck at this task). Oh, I also changed from static training to a walk forward training because this method resembles real life more (rebalance every week). I also thought to myself and had 2 big concerns.

First, i cant just look at the graph, loss curve and common metrics and call it a day, there must be some kind of metrics to capture what i actually want. 2 important kinds of metrics I wanted to see was does the direction of pred match actual data, and is the pred close to actual data in magnitude. So MAE, RMSE (for magnitude); and Directional Accuracy were used. But, I also figured direction must be extra important, because money is more easily lost if given wrong direction, so I added a BCE loss to the loss function, so the actual loss function was MSE + lambda * BCE (lambda represents how important i want direction to be - and I put it quite low because the scale of BCE is already larger than MSE in this case). So now the optimizer penalized for direction loss, which was exactly what i wanted.
Second, I cant just believe entirely in my prediction, uncertainty must also be weighted in the allocation, so I did some Monte Carlo trials to find out exactly how uncertain it was.
(there's some more grid search and cross val to find hyperparameter but i didn't include in this repo)
